version: '3.8'

services:
  namenode: # master node for HDFS
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - "9870:9870" # HDFS web UI
      - "8020:8020" # HDFS client port
    environment:
      - CLUSTER_NAME=fraudout
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020 # HDFS URI. Clients use this to connect to HDFS
      - CORE_CONF_hadoop_proxyuser_root_hosts=* # Allow root user to proxy from any host
      - CORE_CONF_hadoop_proxyuser_root_groups=* # Allow root user to proxy any group
      - CORE_CONF_hadoop_proxyuser_hive_hosts=* # Allow hive user to proxy from any host
      - CORE_CONF_hadoop_proxyuser_hive_groups=* # Allow hive user to proxy any group
      - HDFS_CONF_dfs_namenode_name_dir=file:///hadoop/dfs/name # Namenode storage directory. Mapped to a volume for persistence
      - HDFS_CONF_dfs_replication=1 # Replication factor. Set to 1 for single node setup
    volumes:
      - namenode_data:/hadoop/dfs/name # Persists namenode metadata
    networks:
      - fraudout_network
  
  datanode: # stores actual blocks of files in HDFS
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    environment:
      - CLUSTER_NAME=fraudout # Must match namenode's CLUSTER_NAME
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020 # HDFS URI. Clients use this to connect to HDFS
      - HDFS_CONF_dfs_datanode_data_dir=file:///hadoop/dfs/data # Datanode storage directory. Mapped to a volume for persistence
      - HDFS_CONF_dfs_replication=1 # Replication factor. Set to 1 for single node setup
      - SERVICE_PRECONDITION=namenode:9870 # Ensures datanode starts after namenode is ready
    volumes:
      - datanode_data:/hadoop/dfs/data
    depends_on:
      - namenode
    networks:
      - fraudout_network

  zookeeper:
    image: bitnami/zookeeper:3
    container_name: zookeeper
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    ports:
      - "2181:2181"
    networks:
      - fraudout_network

  kafka:
    image: bitnami/kafka:3
    container_name: kafka
    ports:
      - "9094:9094" # host connection
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 # connects to zookeeper service
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,PLAINTEXT_HOST://:9094 # internal and external listeners
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094 # advertised to clients
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT # protocol mapping
      ALLOW_PLAINTEXT_LISTENER: "yes" # allows non-SSL connections
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_CFG_DEFAULT_REPLICATION_FACTOR: "1"
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    depends_on:
      - zookeeper
    networks:
      - fraudout_network

  spark:
    image: bitnami/spark:3
    container_name: spark
    ports:
      - "8080:8080"
    networks:
      - fraudout_network

# Originally only using Spark, but to connect to Power BI, adding the following is needed
  metastore-db:
    image: postgres:13
    container_name: metastore-db
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    ports:
      - "5432:5432"
    networks:
      - fraudout_network
    volumes:
      - metastore_data:/var/lib/postgresql/data


  hive-metastore:
    image: bde2020/hive:2.3.2
    container_name: hive-metastore
    environment:
      #HIVE_METASTORE_DB_HOSTNAME: metastore-db
      #HIVE_METASTORE_DB_NAME: metastore
      #HIVE_METASTORE_DB_TYPE: postgres
      #HIVE_METASTORE_DB_USER: hive
      #HIVE_METASTORE_DB_PASSWORD: hive
      SERVICE_PRECONDITION: "namenode:9870 metastore-db:5432" # ensures hive-metastore starts after namenode and metastore-db are ready
      CORE_CONF_fs_defaultFS: hdfs://namenode:8020 # HDFS URI. Clients use this to connect to HDFS
      HIVE_SITE_CONF_hive_metastore_uris: thrift://hive-metastore:9083 # Hive metastore Thrift service URI
      HIVE_SITE_CONF_hive_metastore_warehouse_dir: /user/hive/warehouse # Hive warehouse directory in HDFS
      HIVE_SITE_CONF_javax_jdo_option_ConnectionURL: jdbc:postgresql://metastore-db:5432/metastore
      HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName: org.postgresql.Driver
      HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName: hive
      HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword: hive
      #HIVE_AUTO_INIT_SCHEMA: true
      #HIVE_SCHEMA_VERSION: 2.3.0
    # NOTE: NEED TO MANUALLY TYPE THE FOLLOWING COMMAND IN THE CONTAINER
    #command: /opt/hive/bin/hive --service metastore -p 9083 
    #&& /opt/hive/bin/schematool -dbType postgres -initSchema -verbose -userName hive -passWord hive -url jdbc:postgresql://metastore-db:5432/metastore"
    depends_on:
      - namenode
      - metastore-db
      # - schema-init
    ports:
      - "9083:9083" # Hive metastore Thrift service 
    networks:
      - fraudout_network

  hive-server2:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server2
    environment:
      SERVICE_PRECONDITION: "hive-metastore:9083 namenode:9870" # ensures hive-server2 starts after hive-metastore is ready
      CORE_CONF_fs_defaultFS: hdfs://namenode:8020 # HDFS URI. Clients use this to connect to HDFS
      CORE_CONF_hadoop_proxyuser_root_hosts: "*" # Allow root user to proxy from any host
      CORE_CONF_hadoop_proxyuser_root_groups: "*" # Allow root user to proxy any group
      CORE_CONF_hadoop_proxyuser_hive_hosts: "*" # Allow hive user to proxy from any host
      CORE_CONF_hadoop_proxyuser_hive_groups: "*" # Allow hive user to proxy any group
      HIVE_SITE_CONF_hive_metastore_uris: thrift://hive-metastore:9083 # Hive metastore Thrift service URI
      HIVE_SITE_CONF_hive_server2_transport_mode: binary # Use binary transport mode
      HIVE_SITE_CONF_hive_server2_enable_doAs: "false" # Disable impersonation for simplicity
    command: /opt/hive/bin/hiveserver2
    depends_on:
      - hive-metastore
    ports:
      - "10000:10000" # HiveServer2 Thrift service
    networks:
      - fraudout_network

  simulator-1:
    image: simulator
    container_name: simulator-1
    environment:
      PRODUCER_ID: 1
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-2:
    image: simulator
    container_name: simulator-2
    environment:
      PRODUCER_ID: 2
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-3:
    image: simulator
    container_name: simulator-3
    environment:
      PRODUCER_ID: 3
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-4:
    image: simulator
    container_name: simulator-4
    environment:
      PRODUCER_ID: 4
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-5:
    image: simulator
    container_name: simulator-5
    environment:
      PRODUCER_ID: 5
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-6:
    image: simulator
    container_name: simulator-6
    environment:
      PRODUCER_ID: 6
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-7:
    image: simulator
    container_name: simulator-7
    environment:
      PRODUCER_ID: 7
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-8:
    image: simulator
    container_name: simulator-8
    environment:
      PRODUCER_ID: 8
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-9:
    image: simulator
    container_name: simulator-9
    environment:
      PRODUCER_ID: 9
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

  simulator-10:
    image: simulator
    container_name: simulator-10
    environment:
      PRODUCER_ID: 10
    command: poetry run python ingest/marqeta_simulator.py --bootstrap-server kafka:9092 --topic fraudout.txn.raw
    depends_on:
      - kafka
    networks:
      - fraudout_network

networks:
  fraudout_network:

volumes:
  namenode_data:
  datanode_data:
  metastore_data: